<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>WebXR Image Tracking + Video</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
    <style>
      body { margin: 0; overflow: hidden; }
      video { display: none; } /* hide HTML video element */
    </style>
  </head>
  <body>
    <!-- Hidden HTML video element -->
    <video id="arVideo" src="video.mp4" loop playsinline muted></video>

    <script type="module">
      import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.150.0/build/three.module.js';
      import { ARButton } from 'https://cdn.jsdelivr.net/npm/three@0.150.0/examples/jsm/webxr/ARButton.js';

      let camera, scene, renderer, video, videoTexture, videoPlane;
      let trackedImage = null;

      init();
      animate();

      function init() {
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera();

        renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.xr.enabled = true;
        document.body.appendChild(renderer.domElement);

        // AR Button with image tracking feature
        const button = ARButton.createButton(renderer, {
          requiredFeatures: ['image-tracking'],
          trackedImages: [
            {
              image: new URL('marker.jpg', window.location).href,
              widthInMeters: 0.2 // actual width of your printed marker
            }
          ]
        });
        document.body.appendChild(button);

        // Light
        scene.add(new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1));

        // Prepare video element + texture
        video = document.getElementById('arVideo');
        videoTexture = new THREE.VideoTexture(video);
        const material = new THREE.MeshBasicMaterial({ map: videoTexture });
        const geometry = new THREE.PlaneGeometry(0.2, 0.1125); // 16:9 aspect ratio
        videoPlane = new THREE.Mesh(geometry, material);
        videoPlane.visible = false;
        scene.add(videoPlane);

        // Listen for tracking state changes
        renderer.xr.addEventListener('sessionstart', () => {
          const session = renderer.xr.getSession();
          session.addEventListener('trackedevent', (e) => console.log(e)); // debug
        });

        // Update on tracking results
        renderer.xr.addEventListener('update', (event) => {
          const frame = renderer.xr.getFrame();
          const results = frame.getImageTrackingResults ? frame.getImageTrackingResults() : [];
          for (const result of results) {
            const state = result.trackingState;
            const refSpace = renderer.xr.getReferenceSpace();
            const pose = frame.getPose(result.imageSpace, refSpace);

            if (state === "tracked" && pose) {
              trackedImage = result;
              videoPlane.visible = true;
              const mat = new THREE.Matrix4().fromArray(pose.transform.matrix);
              videoPlane.matrix = mat;
              videoPlane.matrixAutoUpdate = false;
              if (video.paused) video.play();
            } else if (state === "emulated" || state === "untracked") {
              videoPlane.visible = false;
              video.pause();
            }
          }
        });

        window.addEventListener('resize', () => renderer.setSize(window.innerWidth, window.innerHeight));
      }

      function animate() {
        renderer.setAnimationLoop(() => {
          renderer.render(scene, camera);
        });
      }
    </script>
  </body>
</html>