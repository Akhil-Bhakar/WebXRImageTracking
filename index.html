<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>WebXR Image Tracking + Video (Aligned + Audio)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"/>
  <style>
    body { margin: 0; overflow: hidden; background: #000; font-family: sans-serif; }
    #enableAudio {
      position: absolute;
      left: 50%;
      transform: translateX(-50%);
      bottom: 24px;
      z-index: 10;
      padding: 12px 18px;
      background: rgba(255,255,255,0.95);
      border-radius: 8px;
      font-weight: 600;
      display: none;
    }
    #msg {
      position: absolute;
      left: 8px; top: 8px;
      color: white;
      text-shadow: 0 0 6px rgba(0,0,0,0.8);
      z-index: 10;
    }
    video { display: none; }
  </style>
</head>
<body>
  <div id="msg">Point camera at the printed marker</div>
  <button id="enableAudio">Enable audio</button>
  <video id="arVideo" src="video.mp4" loop playsinline muted crossorigin="anonymous"></video>

  <script type="module">
    import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.150.0/build/three.module.js';
    import { ARButton } from 'https://cdn.jsdelivr.net/npm/three@0.150.0/examples/jsm/webxr/ARButton.js';

    const MARKER_REAL_WIDTH_M = 0.2061;  // 206.1 mm (match print)
    const MARKER_REAL_HEIGHT_M = 0.1435; // 143.5 mm (match print)

    let camera, scene, renderer, refSpace;
    let videoEl, videoTexture, anchors = new Map();
    const enableAudioBtn = document.getElementById('enableAudio');

    init();
    animate();

    async function init() {
      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera();

      renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
      renderer.setPixelRatio(window.devicePixelRatio);
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.xr.enabled = true;
      renderer.outputEncoding = THREE.sRGBEncoding;
      document.body.appendChild(renderer.domElement);

      // Load marker image as bitmap
      const imgResponse = await fetch('marker.jpg');
      const imgBlob = await imgResponse.blob();
      const imageBitmap = await createImageBitmap(imgBlob);

      const button = ARButton.createButton(renderer, {
        requiredFeatures: ['image-tracking'],
        trackedImages: [{ image: imageBitmap, widthInMeters: MARKER_REAL_WIDTH_M }]
      });
      document.body.appendChild(button);

      videoEl = document.getElementById('arVideo');
      videoEl.loop = true;
      videoEl.muted = true;
      videoEl.setAttribute('playsinline', '');

      videoTexture = new THREE.VideoTexture(videoEl);
      videoTexture.encoding = THREE.sRGBEncoding;
      videoTexture.minFilter = THREE.LinearFilter;
      videoTexture.magFilter = THREE.LinearFilter;

      const mat = new THREE.MeshBasicMaterial({
        map: videoTexture,
        side: THREE.DoubleSide,
        toneMapped: false
      });

      const geom = new THREE.PlaneGeometry(MARKER_REAL_WIDTH_M, MARKER_REAL_HEIGHT_M);
      const plane = new THREE.Mesh(geom, mat);
      plane.rotation.x = -Math.PI / 2; // lay flat on image
      plane.visible = false;

      renderer.xr.addEventListener('sessionstart', () => {
        const session = renderer.xr.getSession();
        session.requestReferenceSpace('local').then(space => refSpace = space);
        enableAudioBtn.style.display = 'block'; // ensure visible
      });

      enableAudioBtn.addEventListener('click', async () => {
        try {
          videoEl.muted = false;
          await videoEl.play();
          enableAudioBtn.style.display = 'none';
        } catch (e) {
          console.warn('Could not enable audio', e);
        }
      });

      // Add the video plane to an anchor dynamically
      renderer.xr.addEventListener('sessionstart', () => {
        scene.add(plane);
        anchors.set(0, plane);
      });

      window.addEventListener('resize', () => {
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    }

    function animate() {
      renderer.setAnimationLoop(render);
    }

    function render(timestamp, frame) {
      if (frame && refSpace && frame.getImageTrackingResults) {
        const results = frame.getImageTrackingResults();

        for (const result of results) {
          const pose = frame.getPose(result.imageSpace, refSpace);
          const plane = anchors.get(result.index);
          if (!plane) continue;

          if (result.trackingState === 'tracked' && pose) {
            plane.matrix.fromArray(pose.transform.matrix);
            plane.matrix.decompose(plane.position, plane.quaternion, plane.scale);
            plane.matrixAutoUpdate = false;

            plane.visible = true;
            if (videoEl.paused) videoEl.play().catch(()=>{});
          } else {
            plane.visible = false;
          }
        }
      }

      renderer.render(scene, camera);
    }
  </script>
</body>
</html>
